# Getting Started with Ollama

Welcome to Ollama! This section will help you get up and running with Ollama quickly.

## Quick Start Guides

```{toctree}
:maxdepth: 1

quickstart
examples
import
```

## Platform-specific Guides

If you're looking for platform-specific getting started guides, check out:

- [Linux Getting Started](linux.md)
- [Windows Getting Started](windows.md)
- [Docker Getting Started](docker.md)

## What is Ollama?

Ollama is a tool that helps you get up and running with large language models locally. It allows you to:

- Run models on your own hardware
- Chat with models through a simple interface
- Import and use various models
- Create and customize your own models

## Next Steps

After getting started, you might want to explore:

- [API Reference](../reference/api.md) to learn how to integrate Ollama with your applications
- [Modelfile Reference](../reference/modelfile.md) to learn how to create and customize models
- [Troubleshooting](../resources/troubleshooting.md) if you encounter any issues